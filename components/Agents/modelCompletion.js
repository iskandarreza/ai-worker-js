export async function completePrompt({
  model = 'gpt-3.5-turbo',
  messages,
  max_tokens = 500,
  temperature = 0.8,
}) {
  /**
   * The function logs and returns the results of a chat completion process, and if there is an error
   * parsing the results, it retries the process.
   * @param res - The parameter `res` is likely a response object returned from a function or API call.
   * It is used as input to the `chatCompletion` function.
   * @returns The function `chatCompletion` returns the variable `results`. If `res` can be parsed as
   * JSON, then `results` will be equal to `res`. Otherwise, `results` will be the result of calling
   * the `getChatCompletion` function.
   */
  async function chatCompletion(res) {
    console.log('\x1b[91m' + JSON.stringify(messages, null, 4) + '\x1b[0m')

    let results = res
    try {
      console.log(
        '\x1b[92m' + JSON.stringify(JSON.parse(results), null, 4) + '\x1b[0m'
      )
    } catch (error) {
      results = await getChatCompletion()
    }
    return results
  }

  /**
   * This function sends a request to the OpenAI API to get a chat completion based on the provided
   * parameters and returns the completed message.
   * @returns The `getChatCompletion` function is returning a Promise that resolves to the content of
   * the message generated by the OpenAI chat completion API. The content is extracted from the
   * response object returned by the API call using the `res.choices[0].message.content` syntax. The
   * `chatCompletion` function is then called with the extracted content as an argument.
   */
  async function getChatCompletion() {
    return await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        Authorization: 'Bearer ' + process.env.NEXT_PUBLIC_OPEN_AI_API_KEY,
      },
      body: JSON.stringify({
        model,
        messages,
        max_tokens,
        temperature,
      }),
    })
      .then((res) => {
        if (res.status === 429) {
          return { status: res.status }
        } else {
          return res.json()
        }
      })
      .then((res) => res.choices[0].message.content)
      .then(chatCompletion)
  }
  return await getChatCompletion()
}

export async function summarizeText({
  model = 'text-davinci-003',
  prompt,
  max_tokens = 500,
  temperature = 0.2,
}) {
  return await fetch('https://api.openai.com/v1/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      Authorization: 'Bearer ' + process.env.NEXT_PUBLIC_OPEN_AI_API_KEY,
    },
    body: JSON.stringify({
      model,
      prompt,
      max_tokens,
      temperature,
    }),
  })
    .then((res) => {
      if (res.status === 429) {
        return { status: res.status }
      } else {
        return res.json()
      }
    })
    .then((res) => res.choices[0].text)
    .then((res) => {
      console.log('\x1b[91m' + prompt + '\x1b[0m')
      console.log('\x1b[92m' + res + '\x1b[0m')
      return res
    })
}

// Unreliable
export async function fixJSON({
  model = 'text-davinci-003',
  prompt,
  max_tokens = 500,
  temperature = 0.0,
}) {
  const _prompt = `Please fix this JSON output:\n${prompt.data}\n\nThe error message received was:\n${prompt.errorMsg}\n\nRespond with the fixed JSON without commentary.`
  return await fetch('https://api.openai.com/v1/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      Authorization: 'Bearer ' + process.env.NEXT_PUBLIC_OPEN_AI_API_KEY,
    },
    body: JSON.stringify({
      model,
      prompt: _prompt,
      max_tokens,
      temperature,
    }),
  })
    .then((res) => res.json())
    .then((res) => res.choices[0].text)
    .then((res) => {
      try {
        console.log(
          '\x1b[91m' + JSON.stringify(JSON.parse(prompt), null, 4) + '\x1b[0m'
        )
        console.log('\x1b[92m' + res + '\x1b[0m')
        return res
      } catch (error) {
        console.error(error)
      }
    })
}
